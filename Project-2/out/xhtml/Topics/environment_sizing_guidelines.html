<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<meta name="copyright" content="(C) Copyright 2019" />
<meta name="DC.rights.owner" content="(C) Copyright 2019" />
<meta name="DC.Type" content="concept" />
<meta name="DC.Title" content="Environment sizing guidelines" />
<meta name="DC.Format" content="XHTML" />
<meta name="DC.Identifier" content="environment_sizing_guidelines" />
<link rel="stylesheet" type="text/css" href="../commonltr.css" />
<title>Environment sizing guidelines</title>
</head>
<body id="environment_sizing_guidelines">

    <h1 class="title topictitle1" id="ariaid-title1">Environment sizing guidelines</h1>

    <div class="body conbody">
        <p class="p">To size an environment precisely, you must understand the factors such as harvest
            frequency, complexity of the source, and use case scenarios that drive application use
            and action execution.</p>

        <p class="p">The general design guidelines for IBM StoredIQ are as follows:</p>

        <ul class="ul" id="environment_sizing_guidelines__ul_gdj_13l_tjb">
            <li class="li">For data servers of the type DataServer - Classic: <p class="p">– One data server for up to 30
                    TBs of data (which can vary based on the number of volumes, objects per volume,
                    and object types). </p>
<p class="p">– Up to 500 volumes per data server</p>
<p class="p"><strong class="ph b">Tip:
                    </strong>When you're sizing an environment that includes Sharepoint data sources,
                    keep in mind that volumes must be defined at Sharepoint site collection level,
                    not the Sharepoint server level.</p>
<p class="p">Up to 150 million objects per data
                    server.</p>
</li>

            <li class="li">One gateway per 50 data servers</li>

            <li class="li">One application server.</li>

            <li class="li">NFS is slightly faster than CIFS for metadata only, but assume CIFS/NFS even for
                this exercise. </li>

            <li class="li">Full-content processing of file (for example, .ZIP, .RAR, .GZ) and email archive
                (.PST, .NSF, .EMX) processing are slower as items must be extracted from the
                archives. If there is a signi³c\u0004nt number of these files in the file system and
                they are not excluded from content processing, the full-content processing rate can
                be too high. Until you have an initial index of the file system, you do not know how
                to weigh full-content processing of archives.</li>

            <li class="li">An object/time metric is appropriate for metadata only NOT computing a hash,
                membership in the National Institute of Standards and Technology (NIST) or
                enumerating objects that are contained in archives. Converting it to a bytes/time
                metric is a function of the average object size and might vary tremendously. An
                average object size of 250 KB was used for the metric that is provided earlier</li>

            <li class="li">A bytes/time metric is appropriate for metadata-only computing a hash and
                full-content processing. The object per second rate can vary tremendously depending
                on the object type and sizes encountered. For example, processing an email or file
                archive is much more expensive than a PDF document.</li>

            <li class="li">Metadata-only not computing a hash, membership in the NIST list, or enumerating
                objects that are contained in archives is requesting only the file-attribute
                information from the NAS. Individual files are not opened and read. The processing
                rate is high, but that does not translate into a large amount of data that traverses
                a network between the NAS and data server. The bytes/time rate does not translate
                into bytes served by the NAS and sent over the network.</li>

            <li class="li">Metadata-only computing a hash, membership in the NIST list, or enumerating objects
                that are contained in archives opens and reads the contents of each file. The
                content of all requested ³les traverses the network between the NAS and data server.
                The maximum load that the data server can place on a NAS is metadata-only
                processing. It requires all file content to be read to compute a hash or enumerate
                objects that are contained in archives. The bytes/time rate translates into bytes
                served up by the NAS and network traffic that must be considered.</li>

            <li class="li"> Full-content processing opens and reads the contents of each file to extract all
                text. The content of all requested files traverses the network between the NAS and
                data server. The processing time to enumerate archives, extract text, index words,
                and extract entities on the data server reduces the rate that data is requested from
                a NAS compared to metadata-only with full hash. The bytes/time rate translates into
                bytes served up by the NAS and network traffic that must be considered.</li>

            <li class="li"> The interrogator process count on the data server for "metadata only not reading
                all content indexing" is set to eight for optimal performance. </li>

            <li class="li">The interrogator process count for all other processing that involves reading all
                content default setting is four per data server.</li>

            <li class="li">The interrogator count can be viewed as the number of client connections that are
                made to a data source actively requesting data. It is important for capacity
                planning for the data source</li>

            <li class="li">The data servers are assumed to be "network close" to the NAS data sources. Network
                latency under 10 ms with at least 1000 Mbps bandwidth is assumed (connected through
                local area network). The data servers need a low latency high-bandwidth connection
                to a NAS data source for acceptable indexing performance.</li>

            <li class="li">The gateway and application stack can be located remotely from the data servers.
                Network connections with latency greater than 10 ms and bandwidth of at least 2+
                Mbps are acceptable. </li>

        </ul>

        <div class="section" id="environment_sizing_guidelines__section_kkq_x3l_tjb"><h2 class="title sectiontitle">VMware requirements</h2>
            
            <div class="p">
                <ul class="ul" id="environment_sizing_guidelines__ul_bch_3jl_tjb">
                    <li class="li">VMware vSphere v5.0 and fix packs or v6.0 and fix packs</li>

                    <li class="li">VMware ESXi v5.0 and fix packs, v6.0 and fix packs, or v6.5 and fix
                        packs.</li>

                    <li class="li">VMware virtual machine hardware version 8.0 or later. For more information,
                        see the VMware product documentation. </li>

                    <li class="li">The appropriate VMware license to enable the required processor cores and
                        memory for the virtual machine. </li>

                </ul>

            </div>

        </div>

    </div>

</body>
</html>